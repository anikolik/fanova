{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc27fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anani\\anaconda3\\envs\\fanova_env\\lib\\site-packages\\scipy\\__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 1.21.5)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import pickle\n",
    "from natsort import natsort_keygen\n",
    "import fanova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258dd66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = f\" \"\n",
    "sys.path.append(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a363cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"Results\"\n",
    "\n",
    "algorithm_names = [\"modCMA-ES\", \"modDE\"]\n",
    "dimensions = [5, 30]\n",
    "budgets = {dim: [50*dim, 100*dim, 300*dim, 500*dim, 1000*dim, 1500*dim] for dim in dimensions}\n",
    "targets = [\"log\"]\n",
    "f_ids = np.arange(1, 25)\n",
    "n_configurations = {\n",
    "    \"modCMA-ES\": 324,\n",
    "    \"modDE\": 576\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e86716",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_hyperparameters(data_path: str):\n",
    "    hyperparameter_values_to_int_map = {\n",
    "                \"modCMA-ES\": {\n",
    "                    \"base_sampler\": {'gaussian': 0, 'sobol': 1, 'halton': 2},\n",
    "                    \"elitist\": {False: 0, True: 1},\n",
    "                    \"local_restart\": {'None': 0, 'IPOP': 1, 'BIPOP': 2},\n",
    "                    \"mirrored\": {'None': 0, 'mirrored': 1, 'mirrored pairwise': 2},\n",
    "                    \"step_size_adaptation\": {'csa': 0, 'psr': 1},\n",
    "                    \"weights_option\": {'default': 0, 'equal': 1, '1/2^lambda': 2},\n",
    "                },\n",
    "                \"modDE\": {\n",
    "                    \"adaptation_method\": {'None': 0, 'shade': 1, 'jDE': 2},\n",
    "                    \"crossover\": {'bin': 0, 'exp': 1},\n",
    "                    \"lpsr\": {False: 0, True: 1},\n",
    "                    \"mutation_base\": {'rand': 0, 'best': 1, 'target': 2},\n",
    "                    \"mutation_n_comps\": {1: 0, 2: 1},\n",
    "                    \"mutation_reference\": {'None': 0, 'pbest': 1, 'best': 2, 'rand': 3},\n",
    "                    \"use_archive\": {False: 0, True: 1},\n",
    "                }\n",
    "            }\n",
    "    # Read data from cvs file\n",
    "    data = pd.read_csv(data_path, index_col=0).reset_index().rename(columns={\"index\": \"configuration_id\"})\n",
    "    data = data.fillna(\"None\")\n",
    "    assert data.isnull().sum().sum() == 0, f\"NaN values exist in the DataFrame. Please check the data after reading. \\n{data[data.isnull().any(axis=1)]}.\"\n",
    "    # Map values to int\n",
    "    for key, value in hyperparameter_values_to_int_map[algorithm_name].items():\n",
    "        data[key] = data[key].map(value)\n",
    "    assert data.isnull().sum().sum() == 0, f\"NaN values exist in the DataFrame. Please check the data after mapping. \\n{data[data.isnull().any(axis=1)]}.\"\n",
    "    # Set configuration_id as index\n",
    "    data.set_index(\"configuration_id\", inplace=True)\n",
    " \n",
    "    return hyperparameter_values_to_int_map, data.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13456ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_performance_data(data_path: str, budget: int, dimension: int, n_configurations:int):\n",
    "    data = []\n",
    "    for configuration_id in range(n_configurations):\n",
    "        # Read data from csv file\n",
    "        filepath = f\"{data_path}/budget_{budget}_conf_{configuration_id}_{dimension}D.csv\"\n",
    "        data_temp = pd.read_csv(filepath).assign(configuration_id=configuration_id)\n",
    "        # Agregate performance\n",
    "        data_temp = data_temp.groupby([\"configuration_id\"]).mean().reset_index()            \n",
    "        data.append(data_temp)\n",
    "    \n",
    "    return pd.concat(data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f54ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(hyperparameters: pd.DataFrame, algorithm_performance: pd.DataFrame, f_id: int):\n",
    "    # Select data based on f_id\n",
    "    algorithm_performance_fid = algorithm_performance[algorithm_performance[\"f_id\"]==f_id].drop(\"f_id\", axis=1)\n",
    "    print(f\"\\nalgorithm_performance_fid:\")\n",
    "    print(algorithm_performance_fid)\n",
    "    # Create dataset\n",
    "    dataset = pd.merge(hyperparameters, algorithm_performance_fid, on=\"configuration_id\")\n",
    "    dataset = dataset.set_index([\"configuration_id\"])\n",
    "    print(\"\\ndataset: \")\n",
    "    print(dataset.head())\n",
    "    print(dataset.shape)\n",
    "\n",
    "    y = dataset[[\"target\"]]\n",
    "    X = dataset.drop(\"target\", axis=1)\n",
    "    X = X.sort_index(axis=1)\n",
    "   \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e05f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hyperparameter_importance(X: pd.DataFrame, y: pd.DataFrame): \n",
    "    # Initialize fanova instance\n",
    "    f = fanova.fANOVA(X.values, y.values, n_trees=100, bootstrapping=True, seed=42)\n",
    "    # Calculate importance\n",
    "    hyperparameters_int = np.arange(X.shape[1]).tolist()\n",
    "    data_dict = {}\n",
    "    # Calculate individual importance\n",
    "    for hyperparameter in hyperparameters_int: \n",
    "        print(hyperparameter)\n",
    "        hyperparameter = (hyperparameter, )\n",
    "        data_dict[hyperparameter] = f.quantify_importance(hyperparameter)[hyperparameter]\n",
    "    # Calculate pairwise importance\n",
    "    for combination in list(itertools.combinations(hyperparameters_int, 2)): \n",
    "        print(combination)\n",
    "        data_dict[combination] = f.quantify_importance(combination)[combination]\n",
    "    # Calculate triple importance\n",
    "    for combination in list(itertools.combinations(hyperparameters_int, 3)): \n",
    "        print(combination)\n",
    "        data_dict[combination] = f.quantify_importance(combination)[combination]\n",
    "    \n",
    "    # Convert result to df\n",
    "    data_df = pd.DataFrame(data_dict).T.reset_index()\n",
    "    hyperparameter_names = X.columns.tolist()                  \n",
    "    hyperparameter_map = {float(i): hyperparameter_names[i] for i in range(len(hyperparameter_names))}\n",
    "    for column in [\"level_0\", \"level_1\", \"level_2\"]:\n",
    "        data_df[column] = data_df[column].map(hyperparameter_map)\n",
    "    data_df = data_df.fillna(\"\")\n",
    "\n",
    "    data_df = data_df.sort_values(by=\"individual importance\", ascending=False)\n",
    "    \n",
    "    return f, data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a56523",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for algorithm_name in algorithm_names:\n",
    "    print(f\"\\nalgorithm_name: {algorithm_name}\")\n",
    "    hyperparameter_values_to_int_map, hyperparameters = load_and_preprocess_hyperparameters(data_path=f\"Data/{algorithm_name}_conf_grid.csv\")\n",
    "    print(\"\\nhyperparameters: \")\n",
    "    print(hyperparameters)\n",
    "    \n",
    "    for dimension, target in itertools.product(dimensions, targets): \n",
    "        print(f\"\\ndimension: {dimension}\")\n",
    "        print(f\"target: {target}\")\n",
    "        for budget in budgets[dimension]:\n",
    "            print(f\"budget: {budget}\")\n",
    "            algorithm_performance = load_and_preprocess_performance_data(f\"Data/{algorithm_name}/{target}\"\n",
    "                                                                         ,budget , dimension, n_configurations[algorithm_name])\n",
    "            print(f\"\\nalgorithm_performance:\")\n",
    "            print(algorithm_performance)\n",
    "            \n",
    "            for f_id in f_ids: \n",
    "                print(f\"f_id: {f_id}\")\n",
    "                # Prepare dataset\n",
    "                X, y = prepare_dataset(hyperparameters, algorithm_performance, f_id)\n",
    "                print(\"\\nX, y: \")\n",
    "                print(X.head())\n",
    "                print(X.shape)\n",
    "                print(y.head())\n",
    "                print(y.shape)\n",
    "                print(X.columns)\n",
    "\n",
    "                # Calculate hyperparameter importance\n",
    "                f, hyperparameters_importance = calculate_hyperparameter_importance(X, y)\n",
    "                print(f\"\\n hyperparameters_importance: \")\n",
    "                print(hyperparameters_importance.head())\n",
    "                # Save\n",
    "                hyperparameters_importance.to_csv(f\"{save_path}/hyperparameter_importance_{algorithm_name}_{dimension}_{budget}_{target}_{f_id}.csv\"\n",
    "                                                 , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fanova_env",
   "language": "python",
   "name": "fanova_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
